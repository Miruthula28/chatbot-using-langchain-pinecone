{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \\\n",
    "    langchain==0.0.354 \\\n",
    "    openai==1.6.1 \\\n",
    "    datasets==2.10.1 \\\n",
    "    pinecone-client==3.1.0 \\\n",
    "    tiktoken==0.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"API_KEY\"]=\"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\"\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=os.environ[\"API_KEY\"],\n",
    "    model='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/mirut/.cache/huggingface/datasets/csv/default-1a90c5bceca93ed0/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Specify the path to your dataset folder\n",
    "dataset_folder_path = r\"C:\\Users\\mirut\\OneDrive\\Desktop\\INT2\\Miruthula's Datasets\\Miruthula's Datasets\\California_Rail_Stations.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\n",
    "    \"csv\",  # Assuming your dataset is in CSV format\n",
    "    data_files=dataset_folder_path,\n",
    "    split=\"train\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['X', 'Y', 'OBJECTID', 'LOCATION', 'STATION', 'CODE', 'ADDRESS', 'ZIP', 'PASS_OP', 'PASS_NETWO', 'COMM_OP', 'COMM_NETWO', 'BUS_ROUTES', 'TRANSIT', 'AIRPORT', 'STATION_TY', 'INTERMODAL', 'DIST', 'CO'],\n",
      "    num_rows: 292\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Print the loaded dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': -13569099.945,\n",
       " 'Y': 4383544.0745,\n",
       " 'OBJECTID': 1,\n",
       " 'LOCATION': 'Parking Garage',\n",
       " 'STATION': 'MONTEREY - Parking Garage',\n",
       " 'CODE': '-',\n",
       " 'ADDRESS': 'Tyler, between Del Monte & Franklin',\n",
       " 'ZIP': 93940,\n",
       " 'PASS_OP': ' ',\n",
       " 'PASS_NETWO': ' ',\n",
       " 'COMM_OP': ' ',\n",
       " 'COMM_NETWO': ' ',\n",
       " 'BUS_ROUTES': '55',\n",
       " 'TRANSIT': ' ',\n",
       " 'AIRPORT': ' ',\n",
       " 'STATION_TY': 2,\n",
       " 'INTERMODAL': 0,\n",
       " 'DIST': 5,\n",
       " 'CO': 'MON'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\") or \"c8b8503f-7230-4bab-a4fa-57f638bfc7c6\"\n",
    "\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.00449,\n",
       " 'namespaces': {'': {'vector_count': 449}},\n",
       " 'total_vector_count': 449}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Creating a vector database\n",
    "\n",
    "import time\n",
    "from pinecone import Pinecone, PodSpec\n",
    "\n",
    "pc = Pinecone(api_key=\"c8b8503f-7230-4bab-a4fa-57f638bfc7c6\")\n",
    "\n",
    "index_name = 'testcone'\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536, \n",
    "        metric='euclidean',\n",
    "        spec=PodSpec(environment=\"gcp-starter\")\n",
    "    )\n",
    "\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "\n",
    "index.describe_index_stats()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=os.environ[\"API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1536)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'this is the first chunk of text',\n",
    "    'then another second chunk of text is here'\n",
    "]\n",
    "\n",
    "res = embed_model.embed_documents(texts)\n",
    "len(res), len(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.13s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm.auto import tqdm  # for progress bar\n",
    "\n",
    "data = dataset.to_pandas()  # this makes it easier to iterate over the dataset\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    # get batch of data\n",
    "    batch = data.iloc[i:i_end]\n",
    "    # generate unique ids for each chunk\n",
    "    ids = [f\"{x['OBJECTID']}-{x['CODE']}\" for i, x in batch.iterrows()]\n",
    "    # get text to embed\n",
    "    texts = [x['LOCATION'] for _, x in batch.iterrows()]\n",
    "    # embed text\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    # get metadata to store in Pinecone\n",
    "    metadata = [\n",
    "        {'text': x['LOCATION'],  \n",
    "         'source': x['STATION_TY'],\n",
    "         'title': x['STATION']} for i, x in batch.iterrows()\n",
    "    ]\n",
    "    # add to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.00449,\n",
       " 'namespaces': {'': {'vector_count': 449}},\n",
       " 'total_vector_count': 449}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"  # the metadata field that contains our text\n",
    "\n",
    "# initialize the vector store object\n",
    "vectorstore = Pinecone(\n",
    "    index, embed_model.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Parking Garage', metadata={'source': 2.0, 'title': 'MONTEREY - Parking Garage'}),\n",
       " Document(page_content='Parking Garage', metadata={'source': 2.0, 'title': 'MONTEREY - Parking Garage'}),\n",
       " Document(page_content='Monterey Marriott Hotel', metadata={'source': 2.0, 'title': 'MONTEREY-Marriott'})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"where is MONTEREY - parking Garage?\"\n",
    "\n",
    "vectorstore.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # get top 3 results from knowledge base\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    # get the text from the results\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # feed into an augmented prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "    Contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    Query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the contexts below, answer the query.\n",
      "\n",
      "    Contexts:\n",
      "    Parking Garage\n",
      "Parking Garage\n",
      "Monterey Marriott Hotel\n",
      "\n",
      "    Query: where is MONTEREY - parking Garage?\n"
     ]
    }
   ],
   "source": [
    "print(augment_prompt(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
